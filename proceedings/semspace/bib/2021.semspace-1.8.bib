@InProceedings{widdows-howell-cohen:2021:SemSpace,
  author    = {Widdows, Dominic  and  Howell, Kristen  and  Cohen, Trevor},
  title     = {Should Semantic Vector Composition be Explicit? Can it be Linear?},
  booktitle      = {Proceedings of the 2021 Workshop on Semantic Spaces at the Intersection of NLP, Physics, and Cognitive Science (SemSpace)},
  month          = {June},
  year           = {2021},
  address        = {Groningen, The Netherlands},
  publisher      = {Association for Computational Linguistics},
  pages     = {76--86},
  abstract  = {Vector representations have become a central element in semantic language modelling, leading to mathematical overlaps with many fields including quantum theory. Compositionality is a core goal for such representations: given representations for 'wet' and 'fish', how should the concept `wet fish' be represented? This position paper surveys this question from two points of view. The first considers the question of whether an explicit mathematical representation can be successful using only tools from within linear algebra, or whether other mathematical tools are needed. The second considers whether semantic vector composition should be explicitly described mathematically, or whether it can be a model-internal side-effect of training a neural network. A third and newer question is whether a compositional model can be implemented on a quantum computer. Given the fundamentally linear nature of quantum mechanics, we propose that these questions are related, and that this survey may help to highlight candidate operations for future quantum implementation.},
  url       = {https://www.aclweb.org/anthology/2021.semspace-1.8}
}

